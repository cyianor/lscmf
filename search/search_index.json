{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Large-scale Collective Matrix Factorization (lsCMF)","text":"<p>This is a package implementing the data integration methodology described in  \"Large-scale Data Integration using Matrix Denoising and Geometric Factor Matching\" (Held, 2024, arXiv:2405.10036 [stat.ME]).</p>"},{"location":"#install-development-version","title":"Install development version","text":"<p>To install the development version of the package run</p> <pre><code>pip install git+https://github.com/cyianor/lscmf.git\n</code></pre>"},{"location":"#install-stable-version","title":"Install stable version","text":"<p>To install the stable version of the package run</p> <pre><code>pip install lscmf\n</code></pre>"},{"location":"getting-started/","title":"Getting started","text":"In\u00a0[1]: Copied! <pre>import lscmf\nfrom numpy.random import default_rng\n\n# Control randomness\nrng = default_rng(42)\n\n# Simulate some data\n# - `viewdims`: Dimensions of each view\n# - `factor_scales`: The strength/singular value of each factor. \n#                    The diagonal of the D matrices in the paper.\n# - `snr`: Signal-to-noise ratio of the noise added to each true signal\n#\n# The function below generates orthogonal matrices V_i and uses the\n# supplied D_ij to form signal matrices V_i D_ij V_j^T. Noise with\n# residual variance controlled by the signal-to-noise ratio is added.\nxs_sim = lscmf.simulate(\n    viewdims={0: 500, 1: 250, 2: 250},\n    factor_scales={\n        (0, 1): [3.0, 2.5, 2.0, 0.0, 0.0],\n        (0, 2): [2.8, 0.0, 0.0, 2.0, 0.0],\n        (1, 2): [1.2, 0.0, 5.0, 0.0, 1.1],\n    },\n    snr=1.0,\n    rng=rng,\n)\n\n# `xs_sim` is a dictionary containing\n# - \"xs_truth\", the true signal matrices\n# - \"xs\", the noisy data\n# - \"vs\", the simulated orthogonal factors\n\n# Create the lscmf object and fit the model to data\nest = lscmf.LargeScaleCMF().fit(xs_sim[\"xs\"])\n</pre> import lscmf from numpy.random import default_rng  # Control randomness rng = default_rng(42)  # Simulate some data # - `viewdims`: Dimensions of each view # - `factor_scales`: The strength/singular value of each factor.  #                    The diagonal of the D matrices in the paper. # - `snr`: Signal-to-noise ratio of the noise added to each true signal # # The function below generates orthogonal matrices V_i and uses the # supplied D_ij to form signal matrices V_i D_ij V_j^T. Noise with # residual variance controlled by the signal-to-noise ratio is added. xs_sim = lscmf.simulate(     viewdims={0: 500, 1: 250, 2: 250},     factor_scales={         (0, 1): [3.0, 2.5, 2.0, 0.0, 0.0],         (0, 2): [2.8, 0.0, 0.0, 2.0, 0.0],         (1, 2): [1.2, 0.0, 5.0, 0.0, 1.1],     },     snr=1.0,     rng=rng, )  # `xs_sim` is a dictionary containing # - \"xs_truth\", the true signal matrices # - \"xs\", the noisy data # - \"vs\", the simulated orthogonal factors  # Create the lscmf object and fit the model to data est = lscmf.LargeScaleCMF().fit(xs_sim[\"xs\"]) <p>Estimates of model parameters are then contained in the <code>LargeScaleCMF</code> object. The estimated singular values can be accessed as shown below.</p> In\u00a0[2]: Copied! <pre>est.ds_\n</pre> est.ds_ Out[2]: <pre>{(0,\n  1): array([-2.98687823,  0.        ,  1.96015864,  0.        ,  2.47498787]),\n (0,\n  2): array([-2.78861131,  1.96604697,  0.        ,  0.        ,  0.        ]),\n (1, 2): array([1.13272996, 0.        , 4.98917765, 1.00988163, 0.        ])}</pre> <p>The estimated factors can be accessed as follows, e.g., for view 0 the first factor is</p> In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\n\ncos_angle = (est.vs_[1][:, 2] * xs_sim[\"vs\"][1][:, 4]).sum()\nprint(f\"Scalar product between estimated and true factor: {cos_angle:.2f}\")\n\nfig = plt.figure(figsize=(8, 3), dpi=100)\nax = fig.add_subplot(111)\n# Negate integrated factor since it was estimated as -v instead of v\nax.hist((-est.vs_[1][:, 2]) - xs_sim[\"vs\"][1][:, 4], bins=30)\nax.set_xlabel(\"Element-wise difference between estimated and true factor\")\nax.set_ylabel(\"Frequency\");\nax.set_title(\"View 1, Integrated factor 3, True factor 5\");\n</pre> import matplotlib.pyplot as plt  cos_angle = (est.vs_[1][:, 2] * xs_sim[\"vs\"][1][:, 4]).sum() print(f\"Scalar product between estimated and true factor: {cos_angle:.2f}\")  fig = plt.figure(figsize=(8, 3), dpi=100) ax = fig.add_subplot(111) # Negate integrated factor since it was estimated as -v instead of v ax.hist((-est.vs_[1][:, 2]) - xs_sim[\"vs\"][1][:, 4], bins=30) ax.set_xlabel(\"Element-wise difference between estimated and true factor\") ax.set_ylabel(\"Frequency\"); ax.set_title(\"View 1, Integrated factor 3, True factor 5\"); <pre>Scalar product between estimated and true factor: 0.00\n</pre> <p>A raw graph-based interface exists as well.</p> In\u00a0[4]: Copied! <pre># Create a view graph to hold the data layout\nG = lscmf.ViewGraph()\n# Add data\n# - `names` need to be provided as an iterable.\n#   These are in general arbitrary, however, in case of\n#   repeated layers, each layer requires a unique name.\n# - `xs` is an iterable to the input data in the same order as\n#   `names`\n# - `viewrels` is an iterable containing tuples describing the\n#    relationships between views contained in data matrices.\nG.add_data_from([\"x01\", \"x02\", \"x12\"], xs_sim[\"xs\"].values(), [(0, 1), (0, 2), (1, 2)])\n\n# Once data is added to the view graph, joint matrices for each\n# view need to be formed and denoising needs to be performed.\n# Different types of shrinkers can be used for denoising and they\n# depend on the type of loss assumed for reconstruction of the\n# signal. See Gavish and Donoho (2017) for details.\n# In the paper, Frobenius loss is assumed, and therefore the resulting\n# `FrobeniusShrinker` is used here.\nlscmf.precompute(G, lscmf.FrobeniusShrinker)\n\n# Finally, matching of factors for each view and merging of the\n# factor match graphs is performed. This function returns\n# the final merged factor match graph.\nH = lscmf.match_factors(G)\n</pre> # Create a view graph to hold the data layout G = lscmf.ViewGraph() # Add data # - `names` need to be provided as an iterable. #   These are in general arbitrary, however, in case of #   repeated layers, each layer requires a unique name. # - `xs` is an iterable to the input data in the same order as #   `names` # - `viewrels` is an iterable containing tuples describing the #    relationships between views contained in data matrices. G.add_data_from([\"x01\", \"x02\", \"x12\"], xs_sim[\"xs\"].values(), [(0, 1), (0, 2), (1, 2)])  # Once data is added to the view graph, joint matrices for each # view need to be formed and denoising needs to be performed. # Different types of shrinkers can be used for denoising and they # depend on the type of loss assumed for reconstruction of the # signal. See Gavish and Donoho (2017) for details. # In the paper, Frobenius loss is assumed, and therefore the resulting # `FrobeniusShrinker` is used here. lscmf.precompute(G, lscmf.FrobeniusShrinker)  # Finally, matching of factors for each view and merging of the # factor match graphs is performed. This function returns # the final merged factor match graph. H = lscmf.match_factors(G) <p>Matches in the factor match graph can be investigated. <code>MatchNode</code>s contain a <code>data_edge</code>, which is a <code>MultiEdge(name, viewrel)</code> corresponding to an input matrix during view graph construction, and a <code>factor</code> which is the factor in the <code>data_edge</code>. Keys of the dictionary are integrated factors.</p> <p>In the example below, <code>MatchNode(data_edge=MultiEdge(x01, (0, 1)), factor=0)</code> is the first factor in data matrix $X_{01}$ which is being associated with integrated factor 0.</p> <p>The numbering of integrated factors is arbitrary and may be non-consecutive.</p> In\u00a0[5]: Copied! <pre>H.graph\n</pre> H.graph Out[5]: <pre>defaultdict(set,\n            {0: {MatchNode(data_edge=MultiEdge(x01, (0, 1)), factor=0),\n              MatchNode(data_edge=MultiEdge(x02, (0, 2)), factor=0),\n              MatchNode(data_edge=MultiEdge(x12, (1, 2)), factor=1)},\n             1: {MatchNode(data_edge=MultiEdge(x01, (0, 1)), factor=2),\n              MatchNode(data_edge=MultiEdge(x12, (1, 2)), factor=0)},\n             3: {MatchNode(data_edge=MultiEdge(x12, (1, 2)), factor=2)},\n             2: {MatchNode(data_edge=MultiEdge(x02, (0, 2)), factor=1)},\n             4: {MatchNode(data_edge=MultiEdge(x01, (0, 1)), factor=1)}})</pre> <p>Reconstruction of $D_{ij}$ and $V_i$ is performed in <code>LargeScaleCMF.fit()</code> and it is recommended to use that interface unless the graph interface is required for a specific reason.</p>"},{"location":"getting-started/#getting-started","title":"Getting started\u00b6","text":""}]}